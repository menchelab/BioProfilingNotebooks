{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "using CSV, StatsBase, Statistics, DataFrames, UMAP, RCall, FreqTables\n",
    "using MultipleTesting, Random, MultivariateStats, Distributed\n",
    "using RMP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "using Dates: now\n",
    "now()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## R Calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@rlibrary ggplot2\n",
    "@rlibrary extrafont\n",
    "@rlibrary viridis\n",
    "@rlibrary heatmaply\n",
    "@rlibrary ggrepel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "R\"\"\"\n",
    "# Used later for MCD computation\n",
    "\n",
    "library(robustbase)\n",
    "\n",
    "# Customize ggplot appearance\n",
    "\n",
    "library(ggplot2)\n",
    "library(extrafont)\n",
    "\n",
    "\n",
    "# Load extra fonts\n",
    "ttf_import(\"/tmp/.fonts\")\n",
    "loadfonts()\n",
    "\n",
    "# Change theme\n",
    "customTheme <- theme_light() + \n",
    "               theme(panel.grid.minor=element_blank(), text=element_text(size=17, family=\"Arial\", colour = \"#333333\"),\n",
    "                     line=element_line(colour = \"#333333\"), \n",
    "                     legend.background = element_rect(fill=alpha('#CCCCCC', 0.1)), legend.key = element_blank())\n",
    "\n",
    "# Change default colors\n",
    "scale_colour_continuous <- function (..., begin = 0.1, end = 0.9, direction = -1, option = \"plasma\", \n",
    "                                     type = getOption(\"ggplot2.continuous.colour\", default = \"viridis\")) {\n",
    "    switch(type, gradient = scale_colour_gradient(...), \n",
    "        viridis = scale_colour_viridis_c(option = option, begin = begin, end = end, direction = direction, ...), \n",
    "        stop(\"Unknown scale type\", call. = FALSE))\n",
    "}\n",
    "scale_color_continuous <- scale_colour_continuous\n",
    "\n",
    "scale_fill_continuous <- function (..., begin = 0.1, end = 0.9, direction = -1, option = \"plasma\", \n",
    "                                     type = getOption(\"ggplot2.continuous.colour\", default = \"viridis\")) {\n",
    "    switch(type, gradient = scale_fill_gradient(...), \n",
    "        viridis = scale_fill_viridis_c(option = option, begin = begin, end = end, direction = direction, ...), \n",
    "        stop(\"Unknown scale type\", call. = FALSE))\n",
    "\n",
    "}\n",
    "\n",
    "cemm_pal = colorRampPalette(c(\"#5A463C\", \"#008CAD\", \"#40B9D4\", \"#D4ECF2\", \"#D2323C\", \"#F8B100\", \"#DFDC00\"))\n",
    "scale_fill_discrete <- function (..., type = \"CeMM\", h = c(0, 360) + 15, c = 100, l = 65, h.start = 0, \n",
    "    direction = 1, na.value = \"grey50\", aesthetics = \"fill\") \n",
    "{\n",
    "    if (type == \"CeMM\"){\n",
    "        discrete_scale(aesthetics, \"CeMM\", cemm_pal, na.value = na.value, ...)\n",
    "    } else {\n",
    "        discrete_scale(aesthetics, \"hue\", hue_pal(h, c, l, h.start, \n",
    "            direction), na.value = na.value, ...)\n",
    "    }\n",
    "}\n",
    "\n",
    "scale_color_discrete <- function (..., type = \"CeMM\", h = c(0, 360) + 15, c = 100, l = 65, h.start = 0, \n",
    "    direction = 1, na.value = \"grey50\", aesthetics = \"colour\") {\n",
    "    if (type == \"CeMM\"){\n",
    "        discrete_scale(aesthetics, \"CeMM\", cemm_pal, na.value = na.value, ...)\n",
    "    } else {\n",
    "        discrete_scale(aesthetics, \"hue\", scales::hue_pal(h, c, l, h.start, \n",
    "            direction), na.value = na.value, ...)\n",
    "    }\n",
    "}\n",
    "scale_colour_discrete <- scale_color_discrete\n",
    "\n",
    "noGridTheme <- function(...){\n",
    "    theme(panel.grid.major=element_blank(), axis.text.x=element_text(size=12), axis.text.y=element_text(size=12),\n",
    "                      axis.line=element_line(color=\"#333333\", size = 0.2), panel.border = element_blank(), ...)\n",
    "}\n",
    "\n",
    "darkTheme <- function(...){\n",
    "    theme(panel.background = element_rect(fill = '#333333'), plot.background = element_rect(fill = '#333333'), \n",
    "          axis.line=element_line(color=\"#CCCCCC\", size = 0.2), \n",
    "          text=element_text(size=17, family=\"Arial\", colour = \"#CCCCCC\"),\n",
    "          line=element_line(colour = \"#CCCCCC\"))\n",
    "}\n",
    "\n",
    "theme_set(customTheme)\n",
    "\n",
    "options(repr.plot.width=10, repr.plot.height=10)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load measurements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations = CSV.read(\"data/transferList.txt\", DataFrame, header = 1, delim = \"\\t\")\n",
    "# Convert plate number to strings to make clear it is an ID and should not be used for computations\n",
    "annotations[!,:DestinationPlate] = string.(annotations[:,:DestinationPlate])\n",
    "# Wells in the transfer list without any compound name are filled with DMSO only\n",
    "annotations[!,:CompoundName][ismissing.(annotations[:,:CompoundName])] .= \"DMSO\"\n",
    "# A non-ASCII characters needs to be converted\n",
    "annotations.CompoundName = replace.(annotations.CompoundName, \"\\xb1\" => s\"Â±\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "annotations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load image data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "image = CSV.read(\"data/compiled_PilotDrugScreen_Image_750.csv\", DataFrame)\n",
    "println(string.(names(image))[1:8])\n",
    "# Number of images and features available\n",
    "println(nrow(image))\n",
    "println(ncol(image))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coarse-grain aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "aggregatedData = CSV.read(\"data/aggregatedData_750cells.csv\", DataFrame);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform aggregated data - Normalization\n",
    "We want to focus on variables that are changing more overall than inside of reference condition (untreated WT)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expAgg = Experiment(aggregatedData, description = \"Median values for aggregated FOV measurements\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filters = Array{RMP.AbstractSelector,1}()\n",
    "# Remove metadata\n",
    "strToRemove = [\"Metadata_Well\", \"CompoundName\", \"Metadata_Field\", \"Metadata_Row\", \"Metadata_Column\"]\n",
    "push!(filters, NameSelector(x -> !any(occursin.(strToRemove, String(x)))))\n",
    "# Remove constant columns\n",
    "push!(filters, Selector(x -> mad(x, normalize = true) != 0, description = \"Remove constant features\"));\n",
    "push!(filters, Selector(x -> mad(x, normalize = true) != 0, \n",
    "                        subset = x -> x.CompoundName .== \"DMSO\", \n",
    "                        description = \"Remove features constant for reference\"))\n",
    "selectFeaturesExperiment!(expAgg, filters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "expTransformed = deepcopy(expAgg)\n",
    "logtransform!(expTransformed)\n",
    "expTransformed.description = \"Transformed values for aggregated FOV measurements\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we apply a correction based on the specific details of the experimental design:\n",
    "All rows and columns include DMSO (negative) controls and we normalize all values based on these matchings controls (same row and column).  \n",
    "\n",
    "This examplifies how to directly modify the data of an `Experiment` object.  \n",
    "\n",
    "NB: One might want to check that more iterations are not needed (cf. Median-polish method)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Normalize on matching DMSO wells median values\n",
    "\n",
    "# Entries in both data frames are matching\n",
    "@assert nrow(aggregatedData) == nrow(getdata(expTransformed))\n",
    "\n",
    "# Copy data before correction\n",
    "ndf = getdata(expTransformed)\n",
    "\n",
    "for (i, (fx, fy)) in enumerate(eachrow(aggregatedData[:,[:Metadata_Row, :Metadata_Column]])) \n",
    "    c1 = aggregatedData.CompoundName .== \"DMSO\"\n",
    "    c2 = aggregatedData.Metadata_Row .== fx\n",
    "    c3 = aggregatedData.Metadata_Column .== fy\n",
    "    @assert sum((c1 .& (c2 .| c3))) > 0\n",
    "    expTransformed.data[i:i, expTransformed.selectedFeatures] .-= \n",
    "        mapcols(median, ndf[(c1 .& (c2 .| c3)),:]) \n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Random.seed!(3895)\n",
    "umTPM = umap(expTransformed)\n",
    "umTPM = convert(DataFrame, umTPM')\n",
    "names!(umTPM, [:UMAP1, :UMAP2]);\n",
    "umTPM.Compound = aggregatedData.CompoundName\n",
    "\n",
    "subsetCompounds = [\"Vinblastine\", \"Pentamidine\", \"JFD00244\", \"DMSO\"]\n",
    "subsetEntries = Bool.(map(sum, eachcol(map(x -> occursin.(x, umTPM.Compound), subsetCompounds)))[1])\n",
    "ggplot(umTPM[subsetEntries,:], aes(:UMAP1, :UMAP2)) + \n",
    "    geom_point(aes(color = :Compound), alpha = 0.8) +\n",
    "    coord_fixed() + \n",
    "    theme(var\"legend.position\"=\"bottom\", var\"legend.spacing.x\" = unit(0.35, \"cm\"), \n",
    "    var\"legend.spacing.y\" = unit(0, \"cm\")) + \n",
    "    guides(color=guide_legend(nrow=3,byrow=true))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distance to DMSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Compute the Mahalanobis Distance to center (MDC)\n",
    "    in a dataset 'data' for a given perturbation of indices 'iPert' \n",
    "    compared to a reference of indices 'iRef'.\"\"\"\n",
    "function MDC(data, iPert, iRef)\n",
    "    setPert = Matrix(data[iPert,:])\n",
    "    setRef = Matrix(data[iRef,:])\n",
    "\n",
    "    mdCenter = dropdims(mean(setRef, dims = 1), dims = 1)\n",
    "    mdCov = cov(setRef)\n",
    "\n",
    "    pertCenter = dropdims(mean(setPert, dims = 1), dims = 1)\n",
    "    \n",
    "    MD = mahalanobis(pertCenter, mdCenter, mdCov)\n",
    "    \n",
    "    return(MD)\n",
    "end\n",
    "\n",
    "\"\"\" Permute labels and compute the Mahalanobis Distance to center (MDC)\n",
    "    in a dataset 'data' for a given perturbation of indices 'iPert' \n",
    "    compared to a reference of indices 'iRef', to create an empirical distribution.\"\"\"\n",
    "function shuffMDC(data, iPert, iRef; nbRep = 250)\n",
    "    setPert = data[iPert,:]\n",
    "    setRef = data[iRef,:]  \n",
    "    set = Matrix(vcat(setRef, setPert))\n",
    "    \n",
    "    function iterShufMD()\n",
    "        nset = size(set, 1)\n",
    "        shuffSet = set[sample(1:nset, nset; replace = false),:]\n",
    "        # Take random subsets of corresponding sizes\n",
    "        shuffSetPert = shuffSet[1:nrow(setPert),:]\n",
    "        shuffSetRef = shuffSet[(nrow(setPert)+1):(nrow(setPert)+nrow(setRef)),:]\n",
    "\n",
    "        # Compute Mahalanobis Distance\n",
    "        \n",
    "        mdCenter = dropdims(mean(shuffSetRef, dims = 1), dims = 1)\n",
    "        mdCov = cov(shuffSetRef)\n",
    "        \n",
    "        pertCenter = dropdims(mean(shuffSetPert, dims = 1), dims = 1)\n",
    "    \n",
    "        MD = mahalanobis(pertCenter, mdCenter, mdCov)\n",
    "        return(MD)\n",
    "    end       \n",
    "    \n",
    "    return(map(x -> iterShufMD(), 1:nbRep))\n",
    "end\n",
    "\n",
    "\"\"\" Compute the median Mahalanobis Distance (MD)\n",
    "    in a dataset 'data' for a given perturbation of indices 'iPert' \n",
    "    compared to a reference of indices 'iRef'.\"\"\"\n",
    "function MD(data, iPert, iRef)\n",
    "    setPert = data[iPert,:]\n",
    "    setRef = Matrix(data[iRef,:])\n",
    "\n",
    "    mdCenter = dropdims(mean(setRef, dims = 1), dims = 1)\n",
    "    mdCov = cov(setRef)\n",
    "    \n",
    "    MD = median(map(x -> mahalanobis(x, mdCenter, mdCov), eachrow(setPert)))\n",
    "    return(MD)\n",
    "end\n",
    "\n",
    "\"\"\" Permute labels and compute the median Mahalanobis Distance (RMD)\n",
    "    in a dataset 'data' for a given perturbation of indices 'iPert' \n",
    "    compared to a reference of indices 'iRef', to create an empirical distribution.\"\"\"\n",
    "function shuffMD(data, iPert, iRef; nbRep = 250)\n",
    "    setPert = data[iPert,:]\n",
    "    setRef = data[iRef,:]  \n",
    "    set = Matrix(vcat(setRef, setPert))\n",
    "    \n",
    "    function iterShufMD()\n",
    "        nset = size(set, 1)\n",
    "        shuffSet = set[sample(1:nset, nset; replace = false),:]\n",
    "        # Take random subsets of corresponding sizes\n",
    "        shuffSetPert = shuffSet[1:nrow(setPert),:]\n",
    "        shuffSetRef = shuffSet[(nrow(setPert)+1):(nrow(setPert)+nrow(setRef)),:]\n",
    "\n",
    "        # Compute Mahalanobis Distance\n",
    "        \n",
    "        mdCenter = dropdims(mean(shuffSetRef, dims = 1), dims = 1)\n",
    "        mdCov = cov(shuffSetRef)\n",
    "\n",
    "        MD = median(map(x -> mahalanobis(x, mdCenter, mdCov), eachrow(DataFrame(shuffSetPert))))\n",
    "        return(MD)\n",
    "    end       \n",
    "    \n",
    "    return(map(x -> iterShufMD(), 1:nbRep))\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\" Compute the median Robust Mahalanobis Distance (RMD)\n",
    "    in a dataset 'data' for a given perturbation of indices 'iPert' \n",
    "    compared to a reference of indices 'iRef'.\n",
    "    See https://e-archivo.uc3m.es/bitstream/handle/10016/24613/ws201710.pdf \"\"\"\n",
    "function RMD(data, iPert, iRef)\n",
    "    setPert = data[iPert,:]\n",
    "    setRef = data[iRef,:] \n",
    "\n",
    "    # Ensure that we have enough points to compute distance\n",
    "    if ((size(setPert)[1] < 2*size(data, 2))|(size(setRef)[1] < 2*size(data, 2)))\n",
    "        return(missing)\n",
    "    end\n",
    "    # NB: having less points than twice the number of dimensions leads to singularity\n",
    "    \n",
    "    # Compute Minimum Covariance Determinant and corresponding Robust Mahalanobis Distance\n",
    "    @rput setRef\n",
    "\n",
    "    R\"\"\"\n",
    "    set.seed(3895)\n",
    "    mcd <- covMcd(setRef)\n",
    "    mcdCenter <- mcd$center\n",
    "    mcdCov <- mcd$cov\n",
    "    \"\"\"\n",
    "    @rget mcdCenter\n",
    "    @rget mcdCov\n",
    "    \n",
    "    RMD = median(map(x -> mahalanobis(x, mcdCenter, mcdCov), eachrow(setPert)))\n",
    "    return(RMD)\n",
    "end\n",
    "\n",
    "\"\"\" Permute labels and compute the median Robust Mahalanobis Distance (RMD)\n",
    "    in a dataset 'data' for a given perturbation of indices 'iPert' \n",
    "    compared to a reference of indices 'iRef', to create an empirical distribution.\"\"\"\n",
    "function shuffRMD(data, iPert, iRef; nbRep = 250)\n",
    "    setPert = data[iPert,:]\n",
    "    setRef = data[iRef,:]  \n",
    "    set = vcat(setRef, setPert)\n",
    "    \n",
    "    # Ensure that we have enough points to compute distance\n",
    "    if ((size(setPert)[1] < 2*size(data, 2))|(size(setRef)[1] < 2*size(data, 2)))\n",
    "        return(repeat([missing], nbRep))\n",
    "    end\n",
    "    # NB: having less points than twice the number of dimensions leads to singularity\n",
    "    \n",
    "    function iterShufRMD()\n",
    "        shuffSet = set[sample(1:nrow(set), nrow(set); replace = false),:]\n",
    "        # Take random subsets of corresponding sizes\n",
    "        shuffSetPert = shuffSet[1:nrow(setPert),:]\n",
    "        shuffSetRef = shuffSet[(nrow(setPert)+1):(nrow(setPert)+nrow(setRef)),:]\n",
    "\n",
    "        # Compute Minimum Covariance Determinant and corresponding Robust Mahalanobis Distance\n",
    "        @rput shuffSetRef\n",
    "        \n",
    "        R\"\"\"\n",
    "        set.seed(3895)\n",
    "        mcd <- covMcd(shuffSetRef)\n",
    "        mcdCenter <- mcd$center\n",
    "        mcdCov <- mcd$cov\n",
    "        \"\"\"\n",
    "        @rget mcdCenter\n",
    "        @rget mcdCov\n",
    "\n",
    "        RMD = median(map(x -> mahalanobis(x, mcdCenter, mcdCov), eachrow(shuffSetPert)))\n",
    "        return(RMD)\n",
    "    end       \n",
    "    \n",
    "    return(map(x -> iterShufRMD(), 1:nbRep))\n",
    "end\n",
    "\n",
    "\"\"\" Compute the Robust Hellinger Distance (RHD)\n",
    "    in a dataset `data` for a given perturbation of indices `iPert` \n",
    "    compared to a reference of indices `iRef`.\"\"\"\n",
    "function RHD(data, iPert, iRef)\n",
    "    setPert = data[iPert,:]\n",
    "    setRef = data[iRef,:] \n",
    "\n",
    "    # Ensure that we have enough points to compute distance\n",
    "    if ((size(setPert)[1] < 2*size(data, 2))|(size(setRef)[1] < 2*size(data, 2)))\n",
    "        return(missing)\n",
    "    end\n",
    "    # NB: having less points than twice the number of dimensions leads to singularity\n",
    "    \n",
    "    # Compute Minimum Covariance Determinant and corresponding Robust Hellinger Distance\n",
    "    @rput setRef\n",
    "    @rput setPert\n",
    "\n",
    "    R\"\"\"\n",
    "    set.seed(3895)\n",
    "    mcd1 <- covMcd(setRef)\n",
    "    mcdCenter1 <- mcd1$center\n",
    "    mcdCov1 <- mcd1$cov\n",
    "    \n",
    "    # We set the seed twice to always\n",
    "    # find the same estimators given\n",
    "    # the same sample\n",
    "    set.seed(3895)\n",
    "    mcd2 <- covMcd(setPert)\n",
    "    mcdCenter2 <- mcd2$center\n",
    "    mcdCov2 <- mcd2$cov\n",
    "    \"\"\"\n",
    "    @rget mcdCenter1\n",
    "    @rget mcdCov1\n",
    "    @rget mcdCenter2\n",
    "    @rget mcdCov2\n",
    "    \n",
    "    RHD = hellinger(mcdCenter1, mcdCov1, mcdCenter2, mcdCov2)\n",
    "    return(RHD)\n",
    "end\n",
    "\n",
    "\"\"\" Permute labels and compute the Robust Hellinger Distance (RHD)\n",
    "    in a dataset `data` for a given perturbation of indices `iPert` \n",
    "    compared to a reference of indices `iRef`, to create an empirical distribution.\"\"\"\n",
    "function shuffRHD(data, iPert, iRef; nbRep = 250)\n",
    "    setPert = data[iPert,:]\n",
    "    setRef = data[iRef,:]  \n",
    "    set = vcat(setRef, setPert)\n",
    "    \n",
    "    # Ensure that we have enough points to compute distance\n",
    "    if ((size(setPert)[1] < 2*size(data, 2))|(size(setRef)[1] < 2*size(data, 2)))\n",
    "        return(repeat([missing], nbRep))\n",
    "    end\n",
    "    # NB: having less points than twice the number of dimensions leads to singularity\n",
    "    \n",
    "    function iterShufRHD()\n",
    "        shuffSet = set[sample(1:nrow(set), nrow(set); replace = false),:]\n",
    "        # Take random subsets of corresponding sizes\n",
    "        shuffSetPert = shuffSet[1:nrow(setPert),:]\n",
    "        shuffSetRef = shuffSet[(nrow(setPert)+1):(nrow(setPert)+nrow(setRef)),:]\n",
    "\n",
    "        # Compute Minimum Covariance Determinant and corresponding Robust Mahalanobis Distance\n",
    "        @rput shuffSetRef\n",
    "        @rput shuffSetPert\n",
    "        \n",
    "        R\"\"\"\n",
    "        set.seed(3895)\n",
    "        mcd <- covMcd(shuffSetRef)\n",
    "        mcdCenter1 <- mcd$center\n",
    "        mcdCov1 <- mcd$cov\n",
    "        \n",
    "        # We set the seed twice to always\n",
    "        # find the same estimators given\n",
    "        # the same sample\n",
    "        set.seed(3895)\n",
    "        mcd <- covMcd(shuffSetPert)\n",
    "        mcdCenter2 <- mcd$center\n",
    "        mcdCov2 <- mcd$cov\n",
    "        \"\"\"\n",
    "        @rget mcdCenter1\n",
    "        @rget mcdCov1        \n",
    "        @rget mcdCenter2\n",
    "        @rget mcdCov2\n",
    "        \n",
    "\n",
    "        RHD = hellinger(mcdCenter1, mcdCov1, mcdCenter2, mcdCov2)\n",
    "        return(RHD)\n",
    "    end       \n",
    "    \n",
    "    return(map(x -> iterShufRHD(), 1:nbRep))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function rmpv(e::Experiment, on::Symbol; \n",
    "                    distance = :RobustHellinger,\n",
    "                    reference = \"DMSO\",\n",
    "                    iterations = 100,\n",
    "                    correction = :FDR)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start with UMAP-based distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expUMAP = Experiment(umTPM, description = \"UMAP projection of profiling data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filters = Array{RMP.AbstractReduce,1}()\n",
    "# Remove (categorical) compound column from analysis\n",
    "push!(filters, NameSelector(x -> x != \"Compound\"))\n",
    "# Remove entries for compounds not present often enough\n",
    "cmpd_to_keep = levels(umTPM.Compound)[freqtable(umTPM.Compound) .>= 4]\n",
    "compare_in(x,y) = x in y\n",
    "Broadcast.broadcasted(::typeof(compare_in), x, y) = broadcast(in, x, Ref(y))\n",
    "push!(filters, Filter(cmpd_to_keep, :Compound, compare = compare_in))\n",
    "# Apply filters\n",
    "filterExperiment!(expUMAP, filters)\n",
    "expUMAP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NB: because the `compare` function of Filter `f` is applied as f.compare.(entries, f.value)\n",
    "the value provided needs to be of the length of the entries or of length 1.  \n",
    "Otherwise, when broadcasting (calling `f.compare` on all elements with `f.compare.`), we need to specify that the `f.value` should be used \"as is\". This is done by overloading the broadcasting of the function. See:   \n",
    "https://discourse.julialang.org/t/how-to-broadcast-over-only-certain-function-arguments/19274/5  \n",
    "Another \"trick\" is to use a function that takes a length 1 value that is in practice not used:  \n",
    "```julia\n",
    "push!(filters, Filter(\"NotUsed\", :Compound, compare = (x,y) -> (x in cmpd_to_keep)))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# The following RMD values are displayed in the following order:\n",
    "selectedCompounds = expUMAP.data[expUMAP.selectedEntries, :Compound]\n",
    "levels(selectedCompounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Actual observed RHD\n",
    "allRHD = map(x -> RHD(getdata(expUMAP), \n",
    "                      selectedCompounds.==x, \n",
    "                      selectedCompounds.==\"DMSO\"), \n",
    "             levels(selectedCompounds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DMSO should be at a distance 0 to itself\n",
    "@assert allRHD[[i for (i,x) in enumerate(levels(selectedCompounds)) if x == \"DMSO\"]] == [0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimize rmpv runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Pkg; Pkg.add(\"BenchmarkTools\")\n",
    "using BenchmarkTools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "@btime allShuffRHD = map(x -> shuffRHD(getdata(expUMAP), selectedCompounds .== x, \n",
    "                                      selectedCompounds .== \"DMSO\", nbRep = 10), \n",
    "                        levels(selectedCompounds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool = CachingPool(workers())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@btime allShuffRHD2 = pmap(x -> shuffRHD(getdata(expUMAP), selectedCompounds .== x, \n",
    "                                      selectedCompounds .== \"DMSO\", nbRep = 10), pool,\n",
    "                        levels(selectedCompounds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@everywhere module StatDistances\n",
    "    using RMP, RCall, DataFrames, StatsBase\n",
    "\n",
    "    \"\"\" Compute the Mahalanobis Distance to center (MDC)\n",
    "        in a dataset 'data' for a given perturbation of indices 'iPert' \n",
    "        compared to a reference of indices 'iRef'.\"\"\"\n",
    "    function MDC(data, iPert, iRef)\n",
    "        setPert = Matrix(data[iPert,:])\n",
    "        setRef = Matrix(data[iRef,:])\n",
    "\n",
    "        mdCenter = dropdims(mean(setRef, dims = 1), dims = 1)\n",
    "        mdCov = cov(setRef)\n",
    "\n",
    "        pertCenter = dropdims(mean(setPert, dims = 1), dims = 1)\n",
    "\n",
    "        MD = mahalanobis(pertCenter, mdCenter, mdCov)\n",
    "\n",
    "        return(MD)\n",
    "    end\n",
    "\n",
    "    \"\"\" Permute labels and compute the Mahalanobis Distance to center (MDC)\n",
    "        in a dataset 'data' for a given perturbation of indices 'iPert' \n",
    "        compared to a reference of indices 'iRef', to create an empirical distribution.\"\"\"\n",
    "    function shuffMDC(data, iPert, iRef; nbRep = 250)\n",
    "        setPert = data[iPert,:]\n",
    "        setRef = data[iRef,:]  \n",
    "        set = Matrix(vcat(setRef, setPert))\n",
    "\n",
    "        function iterShufMD()\n",
    "            nset = size(set, 1)\n",
    "            shuffSet = set[sample(1:nset, nset; replace = false),:]\n",
    "            # Take random subsets of corresponding sizes\n",
    "            shuffSetPert = shuffSet[1:nrow(setPert),:]\n",
    "            shuffSetRef = shuffSet[(nrow(setPert)+1):(nrow(setPert)+nrow(setRef)),:]\n",
    "\n",
    "            # Compute Mahalanobis Distance\n",
    "\n",
    "            mdCenter = dropdims(mean(shuffSetRef, dims = 1), dims = 1)\n",
    "            mdCov = cov(shuffSetRef)\n",
    "\n",
    "            pertCenter = dropdims(mean(shuffSetPert, dims = 1), dims = 1)\n",
    "\n",
    "            MD = mahalanobis(pertCenter, mdCenter, mdCov)\n",
    "            return(MD)\n",
    "        end       \n",
    "\n",
    "        return(map(x -> iterShufMD(), 1:nbRep))\n",
    "    end\n",
    "\n",
    "    \"\"\" Compute the median Mahalanobis Distance (MD)\n",
    "        in a dataset 'data' for a given perturbation of indices 'iPert' \n",
    "        compared to a reference of indices 'iRef'.\"\"\"\n",
    "    function MD(data, iPert, iRef)\n",
    "        setPert = data[iPert,:]\n",
    "        setRef = Matrix(data[iRef,:])\n",
    "\n",
    "        mdCenter = dropdims(mean(setRef, dims = 1), dims = 1)\n",
    "        mdCov = cov(setRef)\n",
    "\n",
    "        MD = median(map(x -> mahalanobis(x, mdCenter, mdCov), eachrow(setPert)))\n",
    "        return(MD)\n",
    "    end\n",
    "\n",
    "    \"\"\" Permute labels and compute the median Mahalanobis Distance (RMD)\n",
    "        in a dataset 'data' for a given perturbation of indices 'iPert' \n",
    "        compared to a reference of indices 'iRef', to create an empirical distribution.\"\"\"\n",
    "    function shuffMD(data, iPert, iRef; nbRep = 250)\n",
    "        setPert = data[iPert,:]\n",
    "        setRef = data[iRef,:]  \n",
    "        set = Matrix(vcat(setRef, setPert))\n",
    "\n",
    "        function iterShufMD()\n",
    "            nset = size(set, 1)\n",
    "            shuffSet = set[sample(1:nset, nset; replace = false),:]\n",
    "            # Take random subsets of corresponding sizes\n",
    "            shuffSetPert = shuffSet[1:nrow(setPert),:]\n",
    "            shuffSetRef = shuffSet[(nrow(setPert)+1):(nrow(setPert)+nrow(setRef)),:]\n",
    "\n",
    "            # Compute Mahalanobis Distance\n",
    "\n",
    "            mdCenter = dropdims(mean(shuffSetRef, dims = 1), dims = 1)\n",
    "            mdCov = cov(shuffSetRef)\n",
    "\n",
    "            MD = median(map(x -> mahalanobis(x, mdCenter, mdCov), eachrow(DataFrame(shuffSetPert))))\n",
    "            return(MD)\n",
    "        end       \n",
    "\n",
    "        return(map(x -> iterShufMD(), 1:nbRep))\n",
    "    end\n",
    "\n",
    "\n",
    "    \"\"\" Compute the median Robust Mahalanobis Distance (RMD)\n",
    "        in a dataset 'data' for a given perturbation of indices 'iPert' \n",
    "        compared to a reference of indices 'iRef'.\n",
    "        See https://e-archivo.uc3m.es/bitstream/handle/10016/24613/ws201710.pdf \"\"\"\n",
    "    function RMD(data, iPert, iRef)\n",
    "        setPert = data[iPert,:]\n",
    "        setRef = data[iRef,:] \n",
    "\n",
    "        # Ensure that we have enough points to compute distance\n",
    "        if ((size(setPert)[1] < 2*size(data, 2))|(size(setRef)[1] < 2*size(data, 2)))\n",
    "            return(missing)\n",
    "        end\n",
    "        # NB: having less points than twice the number of dimensions leads to singularity\n",
    "\n",
    "        # Compute Minimum Covariance Determinant and corresponding Robust Mahalanobis Distance\n",
    "        @rput setRef\n",
    "\n",
    "        R\"\"\"\n",
    "        set.seed(3895)\n",
    "        mcd <- covMcd(setRef)\n",
    "        mcdCenter <- mcd$center\n",
    "        mcdCov <- mcd$cov\n",
    "        \"\"\"\n",
    "        @rget mcdCenter\n",
    "        @rget mcdCov\n",
    "\n",
    "        RMD = median(map(x -> mahalanobis(x, mcdCenter, mcdCov), eachrow(setPert)))\n",
    "        return(RMD)\n",
    "    end\n",
    "\n",
    "    \"\"\" Permute labels and compute the median Robust Mahalanobis Distance (RMD)\n",
    "        in a dataset 'data' for a given perturbation of indices 'iPert' \n",
    "        compared to a reference of indices 'iRef', to create an empirical distribution.\"\"\"\n",
    "    function shuffRMD(data, iPert, iRef; nbRep = 250)\n",
    "        setPert = data[iPert,:]\n",
    "        setRef = data[iRef,:]  \n",
    "        set = vcat(setRef, setPert)\n",
    "\n",
    "        # Ensure that we have enough points to compute distance\n",
    "        if ((size(setPert)[1] < 2*size(data, 2))|(size(setRef)[1] < 2*size(data, 2)))\n",
    "            return(repeat([missing], nbRep))\n",
    "        end\n",
    "        # NB: having less points than twice the number of dimensions leads to singularity\n",
    "\n",
    "        function iterShufRMD()\n",
    "            shuffSet = set[sample(1:nrow(set), nrow(set); replace = false),:]\n",
    "            # Take random subsets of corresponding sizes\n",
    "            shuffSetPert = shuffSet[1:nrow(setPert),:]\n",
    "            shuffSetRef = shuffSet[(nrow(setPert)+1):(nrow(setPert)+nrow(setRef)),:]\n",
    "\n",
    "            # Compute Minimum Covariance Determinant and corresponding Robust Mahalanobis Distance\n",
    "            @rput shuffSetRef\n",
    "\n",
    "            R\"\"\"\n",
    "            set.seed(3895)\n",
    "            mcd <- covMcd(shuffSetRef)\n",
    "            mcdCenter <- mcd$center\n",
    "            mcdCov <- mcd$cov\n",
    "            \"\"\"\n",
    "            @rget mcdCenter\n",
    "            @rget mcdCov\n",
    "\n",
    "            RMD = median(map(x -> mahalanobis(x, mcdCenter, mcdCov), eachrow(shuffSetPert)))\n",
    "            return(RMD)\n",
    "        end       \n",
    "\n",
    "        return(map(x -> iterShufRMD(), 1:nbRep))\n",
    "    end\n",
    "\n",
    "    \"\"\" Compute the Robust Hellinger Distance (RHD)\n",
    "        in a dataset `data` for a given perturbation of indices `iPert` \n",
    "        compared to a reference of indices `iRef`.\"\"\"\n",
    "    function RHD(data, iPert, iRef)\n",
    "        setPert = data[iPert,:]\n",
    "        setRef = data[iRef,:] \n",
    "\n",
    "        # Ensure that we have enough points to compute distance\n",
    "        if ((size(setPert)[1] < 2*size(data, 2))|(size(setRef)[1] < 2*size(data, 2)))\n",
    "            return(missing)\n",
    "        end\n",
    "        # NB: having less points than twice the number of dimensions leads to singularity\n",
    "\n",
    "        # Compute Minimum Covariance Determinant and corresponding Robust Hellinger Distance\n",
    "        @rput setRef\n",
    "        @rput setPert\n",
    "\n",
    "        R\"\"\"\n",
    "        set.seed(3895)\n",
    "        mcd1 <- covMcd(setRef)\n",
    "        mcdCenter1 <- mcd1$center\n",
    "        mcdCov1 <- mcd1$cov\n",
    "\n",
    "        # We set the seed twice to always\n",
    "        # find the same estimators given\n",
    "        # the same sample\n",
    "        set.seed(3895)\n",
    "        mcd2 <- covMcd(setPert)\n",
    "        mcdCenter2 <- mcd2$center\n",
    "        mcdCov2 <- mcd2$cov\n",
    "        \"\"\"\n",
    "        @rget mcdCenter1\n",
    "        @rget mcdCov1\n",
    "        @rget mcdCenter2\n",
    "        @rget mcdCov2\n",
    "\n",
    "        RHD = hellinger(mcdCenter1, mcdCov1, mcdCenter2, mcdCov2)\n",
    "        return(RHD)\n",
    "    end\n",
    "\n",
    "    \"\"\" Permute labels and compute the Robust Hellinger Distance (RHD)\n",
    "        in a dataset `data` for a given perturbation of indices `iPert` \n",
    "        compared to a reference of indices `iRef`, to create an empirical distribution.\"\"\"\n",
    "    function shuffRHD(data, iPert, iRef; nbRep = 250)\n",
    "        setPert = data[iPert,:]\n",
    "        setRef = data[iRef,:]  \n",
    "        set = vcat(setRef, setPert)\n",
    "\n",
    "        # Ensure that we have enough points to compute distance\n",
    "        if ((size(setPert)[1] < 2*size(data, 2))|(size(setRef)[1] < 2*size(data, 2)))\n",
    "            return(repeat([missing], nbRep))\n",
    "        end\n",
    "        # NB: having less points than twice the number of dimensions leads to singularity\n",
    "\n",
    "        function iterShufRHD()\n",
    "            shuffSet = set[sample(1:nrow(set), nrow(set); replace = false),:]\n",
    "            # Take random subsets of corresponding sizes\n",
    "            shuffSetPert = shuffSet[1:nrow(setPert),:]\n",
    "            shuffSetRef = shuffSet[(nrow(setPert)+1):(nrow(setPert)+nrow(setRef)),:]\n",
    "\n",
    "            # Compute Minimum Covariance Determinant and corresponding Robust Mahalanobis Distance\n",
    "            @rput shuffSetRef\n",
    "            @rput shuffSetPert\n",
    "\n",
    "            R\"\"\"\n",
    "            set.seed(3895)\n",
    "            mcd <- covMcd(shuffSetRef)\n",
    "            mcdCenter1 <- mcd$center\n",
    "            mcdCov1 <- mcd$cov\n",
    "\n",
    "            # We set the seed twice to always\n",
    "            # find the same estimators given\n",
    "            # the same sample\n",
    "            set.seed(3895)\n",
    "            mcd <- covMcd(shuffSetPert)\n",
    "            mcdCenter2 <- mcd$center\n",
    "            mcdCov2 <- mcd$cov\n",
    "            \"\"\"\n",
    "            @rget mcdCenter1\n",
    "            @rget mcdCov1        \n",
    "            @rget mcdCenter2\n",
    "            @rget mcdCov2\n",
    "\n",
    "\n",
    "            RHD = hellinger(mcdCenter1, mcdCov1, mcdCenter2, mcdCov2)\n",
    "            return(RHD)\n",
    "        end       \n",
    "\n",
    "        return(map(x -> iterShufRHD(), 1:nbRep))\n",
    "    end\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What to share:\n",
    "* [DONE] levels(selectedCompounds)\n",
    "* [DONE] getdata(expUMAP) -> dataUMAP\n",
    "* [DONE] shuffRHD -> StatDistances.shuffRHD\n",
    "* [DONE] RMP\n",
    "* [DONE] allShuffRHD3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pkg.add(\"ParallelDataTransfer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load required packages in all workers and share variables used in RMPV computation\n",
    "@everywhere using RMP, DataFrames, ParallelDataTransfer\n",
    "sendto(workers(), selectedCompounds=selectedCompounds, \n",
    "                  dataUMAP=getdata(expUMAP))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following commands indeed show that these variables are accessible from all workers:\n",
    "```julia\n",
    "@btime @sync @distributed for i in 1:length(allShuffRHD3)\n",
    "    allShuffRHD3[i] = length(selectedCompounds[(i%length(selectedCompounds))])\n",
    "end\n",
    "```\n",
    "```julia\n",
    "@btime for i in 1:length(allShuffRHD3)\n",
    "    allShuffRHD2[i] = du.UMAP1[i]\n",
    "end\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using SharedArrays\n",
    "allShuffRHD2 = SharedArray{Float64}((length(levels(selectedCompounds)),25));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "@btime @sync @distributed for i in 1:length(allShuffRHD3)\n",
    "    R\"\"\"\n",
    "    # Used later for MCD computation\n",
    "    require(robustbase)\n",
    "    \"\"\"\n",
    "    lvl = levels(selectedCompounds)[i]\n",
    "    allShuffRHD2[i,:] = StatDistances.shuffRHD(dataUMAP, \n",
    "                                             selectedCompounds .== lvl, \n",
    "                                             selectedCompounds .== \"DMSO\", \n",
    "                                             nbRep = 25)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "@btime allShuffRHD = map(x -> shuffRHD(getdata(expUMAP), \n",
    "                                    selectedCompounds .== x, \n",
    "                                    selectedCompounds .== \"DMSO\", \n",
    "                                    nbRep = 25),\n",
    "                      levels(selectedCompounds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allShuffRHD4 = zeros((length(levels(selectedCompounds)),25));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "du = getdata(expUMAP);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@btime for i in 1:length(allShuffRHD3)\n",
    "    R\"\"\"\n",
    "    # Used later for MCD computation\n",
    "    require(robustbase)\n",
    "    \"\"\"\n",
    "    lvl = levels(selectedCompounds)[i]\n",
    "    allShuffRHD4[i,:] = shuffRHD(du, \n",
    "                                 selectedCompounds .== lvl, \n",
    "                                 selectedCompounds .== \"DMSO\", \n",
    "                                 nbRep = 25)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing values need to be handled in real case applications\n",
    "@assert !any(ismissing.(allRHD))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the Robust Morphological Perturbation Value\n",
    "plateRMPV = DataFrame()\n",
    "plateRMPV[:RMPV] = adjust([mean(obs .< sim) for (obs, sim) \n",
    "            in zip(allRHD, allShuffRHD)], BenjaminiHochberg())\n",
    "plateRMPV[:RHD] = allRHD\n",
    "plateRMPV[:Condition] = unique(umND.Condition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allShuffRHD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plateRMPV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display number of positive tests\n",
    "gp = ggplot(plateRMPV) + geom_point(aes(:RMPV, :RHD, color = :Condition)) + \n",
    "    geom_vline(xintercept = 0.05, linetype = \"dashed\")\n",
    "print(gp)\n",
    "savePlot(\"UMAP_RMPV_test_hellinger.pdf\", gp);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.5.3",
   "language": "julia",
   "name": "julia-1.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
